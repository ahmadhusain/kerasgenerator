---
title: "Data Generator for Time Series Models"
author: "R. Dimas Bagas Herlambang"
date: "Last updated on: `r format(Sys.Date(), '%B %e, %Y')`"
bibliography: timeseries.bib
csl: apa.csl
link-citations: yes
output:
  rmarkdown::html_vignette:
    fig_caption: yes
vignette: >
  %\VignetteIndexEntry{Data Generator for Time Series Models}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r setup, include=FALSE}

# chunk opts
knitr::opts_chunk$set(
  warning = FALSE,
  message = FALSE,
  fig.align = "center",
  out.width = "100%"
)

```

Preparing a proper dataset for a supervised time series model in R sometimes could become very complex and tedious. There are some tutorials that already cover this kind of task: check out the tutorial made by [Dancho and Keydana](https://blogs.rstudio.com/tensorflow/posts/2018-06-25-sunspots-lstm/) [-@dancho2018predicting] for basic univariate model fitting without using data generator, and the one made by [Chollet and Allaire](https://blogs.rstudio.com/tensorflow/posts/2017-12-20-time-series-forecasting-with-recurrent-neural-networks/) [-@chollet2017time] for the multivariate model with a custom data generator. However, as you could see from the articles, there are no general framework on how to properly do the data preparation process.

In this article we will show you how `kerasgenerator` could help us in preparing a data generator for supervised time series [`keras`](https://keras.rstudio.com) models.

# Understanding the Time Series Array Shape {#introduction}

To fit a supervised time series model, many of `keras`' functions expect the target and feature data to be in an `array` object with a specific number of dimension. The input `array` need to have three dimension that represent:

1. Sample index
2. Number of timesteps
3. Number of distinct feature

while the output `array` need to have two dimension that represent:

1. Sample index
3. Number of distinct target

To understand better what each dimensions representing, let's follow a quick example using the popular [Internet Traffic Data from 11 European Cities](https://datamarket.com/data/set/232n/internet-traffic-data-in-bits-from-a-private-isp-with-centres-in-11-european-cities-the-data-corresponds-to-a-transatlantic-link-and-was-collected-from-0657-hours-on-7-june-to-1117-hours-on-31-july-2005-data-collected-at-five-minute-intervals#!ds=232n&display=line) dataset, provided by Time Series Data Library [@hyndman2019time]. We can download the datasets using `rdatamarket` package:

```{r}

# import libs
library(lubridate)
library(magrittr)
library(rdatamarket)
library(tidyverse)

# import dataset
traffic_tbl <- dmlist("http://bit.ly/1W1mCQ3")

# readjust datetime
traffic_tbl %<>%
  select(datetime = DateTime, traffic = Value) %>%
  mutate(datetime = ymd_hms(datetime))

# quick check
glimpse(traffic_tbl)

```

The dataset is in a general time series format--it contains a time identifier column, each row representing a data within 5-minutes interval, and it is already regularly ordered. This dataset shows a very interesting time series patterns:

```{r, echo=FALSE, fig.cap="The Internet Traffic dataset"}

# import libs
library(scales)
library(tidyquant)

# plot the last 7 days
traffic_tbl %>%
  ggplot(aes(x = datetime, y = traffic)) +
    geom_line() +
    labs(x = NULL, y = NULL) +
    scale_x_datetime(label = date_format("%a, %b %e, %H:%M:%S")) +
    scale_y_continuous(
      label = unit_format(unit = "M", scale = 1e-09, accuracy = 0.01)
    ) +
    theme_tq()

```

In supervised time series model, we need to define two important parameters for our datasets:

* lookback period:
  
  The lookback period is determining **how many period behind should the targets lookup for its signal**, but it should be noted that **the periods in-between will be ignored**. For example, for target $y_t$ and $l$ lookback, then the target will lookup for feature $x_{t-l}$.
  
* timestep length:

  This parameter define **the length of a sample of feature** that would be considered as a sequence of signal for the target. For example, for feature $x_t$ and $ts$ timesteps length, then the target will lookup for feature $x_t, x_{t-l}, x_{t-2}, ..., x_{t-ts+1}$.

**Note** that the terms that I just mentioned might be differ from other source. While all the version reach to a same understanding, I really suggest you to read the original paper of [Long Short-Term Memory](https://www.bioinf.jku.at/publications/older/2604.pdf) layer [@hochreiter1997long] and other valid resources to reach a better understanding of the terminologies.

Now let's make some illustration using our dataset to make it clear. Supposed that we want to predict the value of 5-minutes total traffic using the hourly pattern in the same minute of previous hour. Say, we pick the last observation of our dataset as our target then the index for our target and its feature will be:

```{r}

# set some parameters
lookback <- 12
timesteps <- 12

# specify the target and feature
target <- nrow(traffic_tbl)
feature_end <- target - lookback
feature_start <- feature_end - timesteps + 1

# check the values
paste("Target:", traffic_tbl$datetime[target])
paste("Feature start:", traffic_tbl$datetime[feature_start])
paste("Feature end:", traffic_tbl$datetime[feature_end])

```

Notice that I set the `feature_start` to be `feature_end - timesteps + 1`. This is because the `timesteps` value is representing the length of a feature--if we don't add `+ 1`, the timesteps would be longer by 1 value. See the following figure for an illustration:

```{r, echo=FALSE, fig.cap="Supervised time series model illustration"}

# convert to date
target_date <- traffic_tbl$datetime[target]
start_date <- traffic_tbl$datetime[feature_start]
end_date <- traffic_tbl$datetime[feature_end]

# illustration
plot_tbl <- traffic_tbl %>%
  tail(12 * 2.25)
  
plot_tbl %>%
  ggplot(aes(x = datetime, y = traffic)) +
    geom_line() +
    geom_point(
      data = traffic_tbl %>%
        filter(datetime %in% c(start_date, end_date, target_date)) %>%
        mutate(id = c("Feature", "Feature", "Target")),
      aes(x = datetime, y = traffic, colour = id)
    ) +
    annotate(
      geom = "text",
      x = target_date,
      y = traffic_tbl$traffic[target] * 1.05,
      label = "Target",
      colour = "darkred",
      angle = 90
    ) +
    annotate(
      geom = "segment",
      x = target_date,
      xend = target_date,
      y = traffic_tbl$traffic[target] * 1.04,
      yend = traffic_tbl$traffic[target] * 1.01,
      colour = "darkred",
      arrow = arrow(length = unit(0.25, "cm"))
    ) +
    annotate(
      geom = "text",
      x = start_date + difftime(end_date, start_date) / 2,
      y = max(plot_tbl$traffic) * 1.01,
      label = glue::glue(
        "A sequence-feature", "\n",
        "with {timesteps} timesteps"
      ),
      colour = "darkblue"
    ) +
    annotate(
      geom = "rect",
      xmin = start_date,
      xmax = end_date,
      ymin = -Inf,
      ymax = Inf,
      alpha = 0.1,
      fill = "darkblue"
    ) +
    labs(x = NULL, y = NULL) +
    guides(colour = FALSE) +
    theme_tq() +
    scale_x_datetime(label = date_format("%b %e, %H:%M:%S")) +
    scale_y_continuous(
      label = unit_format(unit = "M", scale = 1e-09, accuracy = 0.01)
    ) +
    scale_colour_manual(
      values = c("Feature" = "darkblue", "Target" = "darkred"),
      breaks = c("Feature", "Target")
    )

```

If we follow this format, then we could convert the data into a proper `array` matrices like this:

```{r}

# container arrays
x_array <- array(0, dim = c(1, timesteps, 1))
y_array <- array(0, dim = c(1, 1))

# specify the row indices
y_row <- target
x_row <- y_row - lookback

# adjust the x indices according to the timesteps
x_indices <- seq(x_row - timesteps + 1, x_row)

# convert the table into matrix
traffic_matrix <- data.matrix(traffic_tbl)

# fill the arrays
x_array[1, , 1] <- traffic_matrix[x_indices, 2]
y_array[1, 1] <- traffic_matrix[y_row, 2]

```

Let's confirm the structure and content inside the arrays:

```{r}

# check the structure
str(x_array)
str(y_array)

```

Basically, the [`series_generator()`](/reference/series_generator) function is transforming your data into the same format as in above explanations; [`forecast_generator()`]((/reference/forecast_generator)) also works in a similar way, but have a different point of view (see [forecasting section](#forecast) for further explanation). Let's take a look on how those functions in action in the following sections.

# Fitting a Time Series Model {#fitting}

To build a time series data generator, we need to specify some parameters related to our model. Let's start by the supervised time series model specifications. In addition to `lookback` and `timesteps`, we also need to specify the `x` and `y` variables, which in this case are both `"traffic"` variable:

```{r}

# the x and y
x <- "traffic"
y <- "traffic"

# supervised parameter
lookback <- 12
timesteps <- 12

```

Another parameters that neet to be set are related to our cross-validation settings. In order to split the dataset into train, validation, and test dataset, the `series_generator()` need to know the `start_index` and `end_index`. First, let's start by defining each sample sizes:

```{r}

# number of train-val-test sample
train_size <- 12 * 24 * 7 * 4
val_size <- 12 * 24 * 7
test_size <- 12 * 24 * 7

```

Then we can specify the sample indices according to its size. Note that you can choose to sample the row indices, but I really suggest to follow the best practice by splitting the samples according to its time order:

```{r}

# train-val row indices
test_end <- nrow(traffic_tbl)
test_start <- test_end - test_size + 1

val_end <- test_start - 1
val_start <- val_end - val_size + 1

train_end <- val_start - 1
train_start <- train_end - train_size + 1

```

The last but not least, we need to specify the `batch_size` and the number of `steps` in order to see the full data for each sample:

```{r}

# batch size
batch_size <- 12 * 24

# number of steps to see full data
train_steps <- ceiling(train_size / batch_size)
val_steps <- ceiling(val_size / batch_size)
test_steps <- ceiling(test_size / batch_size)

```

**Note** that I wrap the `size / batch_size` with `ceiling` function. This is necessary to ensure that Keras' generator function will see all observation.

Before we define the data generators, let's define a custom function for data preprocessing on the fly using [`recipes`](https://tidymodels.github.io/recipes/) functions:

```{r}

# import libs
library(recipes)

# recipe: square root, center, scale
recipe_obj <- recipe(traffic ~ ., traffic_tbl[train_start:train_end, ]) %>%
  step_sqrt(all_outcomes()) %>%
  step_center(all_outcomes()) %>%
  step_scale(all_outcomes()) %>%
  prep()

# custom preprocess function
prep_funs <- function(data) {
  
  # preprocess
  newdata <- bake(
    object = recipe_obj,
    new_data = data
  )
  
  # return the processed data
  return(newdata)
  
}

```

Finally, we could start to make generators for the train and validation data:

```{r}

# import libs
library(kerasgenerator)

# data generator
train_gen <- series_generator(
  data = traffic_tbl,
  y = y,
  x = x,
  lookback = lookback,
  timesteps = timesteps,
  start_index = train_start,
  end_index = train_end,
  batch_size = batch_size,
  return_target = TRUE,
  prep_funs = prep_funs
)

val_gen <- series_generator(
  data = traffic_tbl,
  y = y,
  x = x,
  lookback = lookback,
  timesteps = timesteps,
  start_index = val_start,
  end_index = val_end,
  batch_size = batch_size,
  return_target = TRUE,
  prep_funs = prep_funs
)

```

Let's see how the generators work with Keras' model. First, let's define our time series Keras model:

```{r}

# import libs
library(keras)

# initiate a sequential model
model <- keras_model_sequential()

# define the model
model %>%
  
  # layer lstm
  layer_lstm(
    name = "lstm1",
    input_shape = list(timesteps, length(x)),
    units = 128,
    dropout = 0.1,
    recurrent_dropout = 0.2,
    return_sequences = TRUE
  ) %>%
  
  layer_lstm(
    name = "lstm2",
    units = 64,
    dropout = 0.1,
    recurrent_dropout = 0.2,
    return_sequences = TRUE
  ) %>%
  
  layer_lstm(
    name = "lstm3",
    units = 32,
    dropout = 0.1,
    recurrent_dropout = 0.2,
    return_sequences = FALSE
  ) %>%
  
  # layer output
  layer_dense(
    name = "output",
    units = length(y)
  )

# compile the model
model %>% compile(
  optimizer = "rmsprop",
  loss = "mse"
)

# model summary
summary(model)

```

Since we use a data generator, use [`fit_generator()`]((https://keras.rstudio.com/reference/fit_generator.html)) function to fit the model:

```{r}

# set number of epochs
epochs <- 30

# model fitting
history <- model %>% fit_generator(
  generator = train_gen,
  steps_per_epoch = train_steps,
  validation_data = val_gen,
  validation_steps = val_steps,
  epochs = epochs
)

# history plot
plot(history)

```

You can also pass the generator to [`evaluate_generator()`]((https://keras.rstudio.com/reference/evaluate_generator.html)) to evaluate the results. Let's try to evaluate on the test dataset:

```{r}

# test data generator
test_gen <- series_generator(
  data = traffic_tbl,
  y = y,
  x = x,
  lookback = lookback,
  timesteps = timesteps,
  start_index = test_start,
  end_index = test_end,
  batch_size = batch_size,
  return_target = TRUE,
  prep_funs = prep_funs
)

# evaluate on test dataset
model %>% evaluate_generator(
  generator = test_gen,
  steps = test_steps
)

```

# Forecasting using Data Generator {#forecast}

Like in [`series_generator()`](/reference/series_generator) function, we need to specify some parameters for [`forecast_generator()`](/reference/forecast_generator):

```{r}

# forecast horizon
horizon <- 12

# forecast indices
last_index <- nrow(traffic_tbl)

# number of steps to see full data
fcast_steps <- ceiling(horizon / batch_size)

```

**Note that the forecast `horizon` should not be greater than the value of `lookback` if you want to forecast from the last observation**.

Then, we can proceed to define the generator for forecasting and pass it to [`predict_generator()`]((https://keras.rstudio.com/reference/predict_generator.html)) function.

```{r}

# forecast generator
fcast_gen <- forecast_generator(
  data = traffic_tbl,
  x = x,
  lookback = lookback,
  timesteps = timesteps,
  last_index = last_index,
  horizon = horizon,
  batch_size = batch_size,
  prep_funs = prep_funs
)

# forecast using generator
fcast <- model %>% predict_generator(
  generator = fcast_gen,
  steps = fcast_steps
)

# check the content
str(fcast)

```

**BONUS:** you can reconvert the forecast output like this

```{r}

# import libs
library(timetk)

# make future time series index
fcast_index <- tk_make_future_timeseries(
  idx = traffic_tbl$datetime,
  n_future = horizon
)

# get recipe values for revert back
recipe_center <- recipe_obj$steps[[2]]$means["traffic"]
recipe_scale <- recipe_obj$steps[[3]]$sds["traffic"]

# check the forecast output
fcast %>%
  as.data.frame() %>%
  setNames("traffic") %>%
  mutate(
    datetime = fcast_index,
    traffic = (traffic * recipe_scale + recipe_center) ^ 2
  ) %>%
  select(datetime, traffic) %>%
  head()

```


# References {#reference}
